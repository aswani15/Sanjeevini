{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFisherNet_DR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswani15/Sanjeevini/blob/master/DeepFisherNet_DR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea7iqPMfwUPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bbac804-b5c8-466b-c533-6370bb47a785"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jJFD1ppbtXG",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t054u6eewh6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from argparse import ArgumentParser,SUPPRESS\n",
        "import time\n",
        "import yaml\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torch.autograd.variable import Variable\n",
        "import torch.nn as nn\n",
        "from torchvision.models import *\n",
        "from torch.autograd.variable import Variable\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhFGi9asA9P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, inplanes, planes, stride=1, mode='NORM', k=1, dilation=1):\n",
        "        \"\"\"\n",
        "        Pre-act residual block, the middle transformations are bottle-necked\n",
        "        :param inplanes:\n",
        "        :param planes:\n",
        "        :param stride:\n",
        "        :param downsample:\n",
        "        :param mode: NORM | UP\n",
        "        :param k: times of additive\n",
        "        \"\"\"\n",
        "\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.k = k\n",
        "\n",
        "        btnk_ch = planes // 4\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, btnk_ch, kernel_size=1, bias=False)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(btnk_ch)\n",
        "        self.conv2 = nn.Conv2d(btnk_ch, btnk_ch, kernel_size=3, stride=stride, padding=dilation,\n",
        "                               dilation=dilation, bias=False)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(btnk_ch)\n",
        "        self.conv3 = nn.Conv2d(btnk_ch, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        if mode == 'UP':\n",
        "            self.shortcut = None\n",
        "        elif inplanes != planes or stride > 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.BatchNorm2d(inplanes),\n",
        "                self.relu,\n",
        "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = None\n",
        "\n",
        "    def _pre_act_forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        if self.mode == 'UP':\n",
        "            residual = self.squeeze_idt(x)\n",
        "        elif self.shortcut is not None:\n",
        "            residual = self.shortcut(residual)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        return out\n",
        "\n",
        "    def squeeze_idt(self, idt):\n",
        "        n, c, h, w = idt.size()\n",
        "        return idt.view(n, c // self.k, self.k, h, w).sum(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self._pre_act_forward(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhMEu6iqA9fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import torch\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgR9j9smA9m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__all__ = ['fish']\n",
        "\n",
        "\n",
        "class Fish(nn.Module):\n",
        "    def __init__(self, block, num_cls=2, num_down_sample=5, num_up_sample=3, trans_map=(2, 1, 0, 6, 5, 4),\n",
        "                 network_planes=None, num_res_blks=None, num_trans_blks=None):\n",
        "        super(Fish, self).__init__()\n",
        "        self.block = block\n",
        "        self.trans_map = trans_map\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.down_sample = nn.MaxPool2d(2, stride=2)\n",
        "        self.num_cls = num_cls\n",
        "        self.num_down = num_down_sample\n",
        "        self.num_up = num_up_sample\n",
        "        self.network_planes = network_planes[1:]\n",
        "        self.depth = len(self.network_planes)\n",
        "        self.num_trans_blks = num_trans_blks\n",
        "        self.num_res_blks = num_res_blks\n",
        "        self.fish = self._make_fish(network_planes[0])\n",
        "\n",
        "    def _make_score(self, in_ch, out_ch=2, has_pool=False):\n",
        "        bn = nn.BatchNorm2d(in_ch)\n",
        "        relu = nn.ReLU(inplace=True)\n",
        "        conv_trans = nn.Conv2d(in_ch, in_ch // 2, kernel_size=1, bias=False)\n",
        "        bn_out = nn.BatchNorm2d(in_ch // 2)\n",
        "        conv = nn.Sequential(bn, relu, conv_trans, bn_out, relu)\n",
        "        if has_pool:\n",
        "            fc = nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(1),\n",
        "                nn.Conv2d(in_ch // 2, out_ch, kernel_size=1, bias=True))\n",
        "        else:\n",
        "            fc = nn.Conv2d(in_ch // 2, out_ch, kernel_size=1, bias=True)\n",
        "        return [conv, fc]\n",
        "\n",
        "    def _make_se_block(self, in_ch, out_ch):\n",
        "        bn = nn.BatchNorm2d(in_ch)\n",
        "        sq_conv = nn.Conv2d(in_ch, out_ch // 16, kernel_size=1)\n",
        "        ex_conv = nn.Conv2d(out_ch // 16, out_ch, kernel_size=1)\n",
        "        return nn.Sequential(bn,\n",
        "                             nn.ReLU(inplace=True),\n",
        "                             nn.AdaptiveAvgPool2d(1),\n",
        "                             sq_conv,\n",
        "                             nn.ReLU(inplace=True),\n",
        "                             ex_conv,\n",
        "                             nn.Sigmoid())\n",
        "\n",
        "    def _make_residual_block(self, inplanes, outplanes, nstage, is_up=False, k=1, dilation=1):\n",
        "        layers = []\n",
        "\n",
        "        if is_up:\n",
        "            layers.append(self.block(inplanes, outplanes, mode='UP', dilation=dilation, k=k))\n",
        "        else:\n",
        "            layers.append(self.block(inplanes, outplanes, stride=1))\n",
        "        for i in range(1, nstage):\n",
        "            layers.append(self.block(outplanes, outplanes, stride=1, dilation=dilation))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_stage(self, is_down_sample, inplanes, outplanes, n_blk, has_trans=True,\n",
        "                    has_score=False, trans_planes=0, no_sampling=False, num_trans=2, **kwargs):\n",
        "        sample_block = []\n",
        "        if has_score:\n",
        "            sample_block.extend(self._make_score(outplanes, outplanes * 2, has_pool=False))\n",
        "\n",
        "        if no_sampling or is_down_sample:\n",
        "            res_block = self._make_residual_block(inplanes, outplanes, n_blk, **kwargs)\n",
        "        else:\n",
        "            res_block = self._make_residual_block(inplanes, outplanes, n_blk, is_up=True, **kwargs)\n",
        "\n",
        "        sample_block.append(res_block)\n",
        "\n",
        "        if has_trans:\n",
        "            trans_in_planes = self.in_planes if trans_planes == 0 else trans_planes\n",
        "            sample_block.append(self._make_residual_block(trans_in_planes, trans_in_planes, num_trans))\n",
        "\n",
        "        if not no_sampling and is_down_sample:\n",
        "            sample_block.append(self.down_sample)\n",
        "        elif not no_sampling:  # Up-Sample\n",
        "            sample_block.append(self.upsample)\n",
        "\n",
        "        return nn.ModuleList(sample_block)\n",
        "\n",
        "    def _make_fish(self, in_planes):\n",
        "        def get_trans_planes(index):\n",
        "            map_id = self.trans_map[index-self.num_down-1] - 1\n",
        "            p = in_planes if map_id == -1 else cated_planes[map_id]\n",
        "            return p\n",
        "\n",
        "        def get_trans_blk(index):\n",
        "            return self.num_trans_blks[index-self.num_down-1]\n",
        "\n",
        "        def get_cur_planes(index):\n",
        "            return self.network_planes[index]\n",
        "\n",
        "        def get_blk_num(index):\n",
        "            return self.num_res_blks[index]\n",
        "\n",
        "        cated_planes, fish = [in_planes] * self.depth, []\n",
        "        for i in range(self.depth):\n",
        "            # even num for down-sample, odd for up-sample\n",
        "            is_down, has_trans, no_sampling = i not in range(self.num_down, self.num_down+self.num_up+1),\\\n",
        "                                              i > self.num_down, i == self.num_down\n",
        "            cur_planes, trans_planes, cur_blocks, num_trans =\\\n",
        "                get_cur_planes(i), get_trans_planes(i), get_blk_num(i), get_trans_blk(i)\n",
        "\n",
        "            stg_args = [is_down, cated_planes[i - 1], cur_planes, cur_blocks]\n",
        "\n",
        "            if is_down or no_sampling:\n",
        "                k, dilation = 1, 1\n",
        "            else:\n",
        "                k, dilation = cated_planes[i - 1] // cur_planes, 2 ** (i-self.num_down-1)\n",
        "\n",
        "            sample_block = self._make_stage(*stg_args, has_trans=has_trans, trans_planes=trans_planes,\n",
        "                                            has_score=(i==self.num_down), num_trans=num_trans, k=k, dilation=dilation,\n",
        "                                            no_sampling=no_sampling)\n",
        "            if i == self.depth - 1:\n",
        "                sample_block.extend(self._make_score(cur_planes + trans_planes, out_ch=self.num_cls, has_pool=True))\n",
        "            elif i == self.num_down:\n",
        "                sample_block.append(nn.Sequential(self._make_se_block(cur_planes*2, cur_planes)))\n",
        "\n",
        "            if i == self.num_down-1:\n",
        "                cated_planes[i] = cur_planes * 2\n",
        "            elif has_trans:\n",
        "                cated_planes[i] = cur_planes + trans_planes\n",
        "            else:\n",
        "                cated_planes[i] = cur_planes\n",
        "            fish.append(sample_block)\n",
        "        return nn.ModuleList(fish)\n",
        "\n",
        "    def _fish_forward(self, all_feat):\n",
        "        def _concat(a, b):\n",
        "            return torch.cat([a, b], dim=1)\n",
        "\n",
        "        def stage_factory(*blks):\n",
        "            def stage_forward(*inputs):\n",
        "                if stg_id < self.num_down:  # tail\n",
        "                    tail_blk = nn.Sequential(*blks[:2])\n",
        "                    return tail_blk(*inputs)\n",
        "                elif stg_id == self.num_down:\n",
        "                    score_blks = nn.Sequential(*blks[:2])\n",
        "                    score_feat = score_blks(inputs[0])\n",
        "                    att_feat = blks[3](score_feat)\n",
        "                    return blks[2](score_feat) * att_feat + att_feat\n",
        "                else:  # refine\n",
        "                    feat_trunk = blks[2](blks[0](inputs[0]))\n",
        "                    feat_branch = blks[1](inputs[1])\n",
        "                return _concat(feat_trunk, feat_branch)\n",
        "            return stage_forward\n",
        "\n",
        "        stg_id = 0\n",
        "        # tail:\n",
        "        while stg_id < self.depth:\n",
        "            stg_blk = stage_factory(*self.fish[stg_id])\n",
        "            if stg_id <= self.num_down:\n",
        "                in_feat = [all_feat[stg_id]]\n",
        "            else:\n",
        "                trans_id = self.trans_map[stg_id-self.num_down-1]\n",
        "                in_feat = [all_feat[stg_id], all_feat[trans_id]]\n",
        "\n",
        "            all_feat[stg_id + 1] = stg_blk(*in_feat)\n",
        "            stg_id += 1\n",
        "            # loop exit\n",
        "            if stg_id == self.depth:\n",
        "                score_feat = self.fish[self.depth-1][-2](all_feat[-1])\n",
        "                score = self.fish[self.depth-1][-1](score_feat)\n",
        "                return score\n",
        "\n",
        "    def forward(self, x):\n",
        "        all_feat = [None] * (self.depth + 1)\n",
        "        all_feat[0] = x\n",
        "        return self._fish_forward(all_feat)\n",
        "\n",
        "\n",
        "class FishNet(nn.Module):\n",
        "    def __init__(self, block, **kwargs):\n",
        "        super(FishNet, self).__init__()\n",
        "\n",
        "        inplanes = kwargs['network_planes'][0]\n",
        "        # resolution: 224x224\n",
        "        self.conv1 = self._conv_bn_relu(3, inplanes // 2, stride=2)\n",
        "        self.conv2 = self._conv_bn_relu(inplanes // 2, inplanes // 2)\n",
        "        self.conv3 = self._conv_bn_relu(inplanes // 2, inplanes)\n",
        "        self.pool1 = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "        # construct fish, resolution 56x56\n",
        "        self.fish = Fish(block, **kwargs)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _conv_bn_relu(self, in_ch, out_ch, stride=1):\n",
        "        return nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=stride, bias=False),\n",
        "                             nn.BatchNorm2d(out_ch),\n",
        "                             nn.ReLU(inplace=True))\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool1(x)\n",
        "        score = self.fish(x)\n",
        "        # 1*1 output\n",
        "        out = score.view(x.size(0), -1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def fish(**kwargs):\n",
        "    return FishNet(Bottleneck, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUyBCxlLA9p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fishnet99(**kwargs):\n",
        "    \"\"\"\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    net_cfg = {\n",
        "        #  input size:   [224, 56, 28,  14  |  7,   7,  14,  28 | 56,   28,  14]\n",
        "        # output size:   [56,  28, 14,   7  |  7,  14,  28,  56 | 28,   14,   7]\n",
        "        #                  |    |    |   |     |    |    |    |    |     |    |\n",
        "        'network_planes': [64, 128, 256, 512, 512, 512, 384, 256, 320, 832, 1600],\n",
        "        'num_res_blks': [2, 2, 6, 2, 1, 1, 1, 1, 2, 2],\n",
        "        'num_trans_blks': [1, 1, 1, 1, 1, 4],\n",
        "        'num_cls': 2,\n",
        "        'num_down_sample': 3,\n",
        "        'num_up_sample': 3,\n",
        "    }\n",
        "    cfg = {**net_cfg, **kwargs}\n",
        "    return fish(**cfg)\n",
        "\n",
        "\n",
        "def fishnet150(**kwargs):\n",
        "    \"\"\"\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    net_cfg = {\n",
        "        #  input size:   [224, 56, 28,  14  |  7,   7,  14,  28 | 56,   28,  14]\n",
        "        # output size:   [56,  28, 14,   7  |  7,  14,  28,  56 | 28,   14,   7]\n",
        "        #                  |    |    |   |     |    |    |    |    |     |    |\n",
        "        'network_planes': [64, 128, 256, 512, 512, 512, 384, 256, 320, 832, 1600],\n",
        "        'num_res_blks': [2, 4, 8, 4, 2, 2, 2, 2, 2, 4],\n",
        "        'num_trans_blks': [2, 2, 2, 2, 2, 4],\n",
        "        'num_cls': 2,\n",
        "        'num_down_sample': 3,\n",
        "        'num_up_sample': 3,\n",
        "    }\n",
        "    cfg = {**net_cfg, **kwargs}\n",
        "    return fish(**cfg)\n",
        "\n",
        "\n",
        "def fishnet201(**kwargs):\n",
        "    \"\"\"\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    net_cfg = {\n",
        "        #  input size:   [224, 56, 28,  14  |  7,   7,  14,  28 | 56,   28,  14]\n",
        "        # output size:   [56,  28, 14,   7  |  7,  14,  28,  56 | 28,   14,   7]\n",
        "        #                  |    |    |   |     |    |    |    |    |     |    |\n",
        "        'network_planes': [64, 128, 256, 512, 512, 512, 384, 256, 320, 832, 1600],\n",
        "        'num_res_blks': [3, 4, 12, 4, 2, 2, 2, 2, 3, 10],\n",
        "        'num_trans_blks': [2, 2, 2, 2, 2, 9],\n",
        "        'num_cls': 2,\n",
        "        'num_down_sample': 3,\n",
        "        'num_up_sample': 3,\n",
        "    }\n",
        "    cfg = {**net_cfg, **kwargs}\n",
        "    return fish(**cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tc-bgSQA9sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "def calc_flops(model, input_size):\n",
        "    global USE_GPU\n",
        "\n",
        "    def conv_hook(self, input, output):\n",
        "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
        "        output_channels, output_height, output_width = output[0].size()\n",
        "\n",
        "        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups) * (\n",
        "            2 if multiply_adds else 1)\n",
        "        bias_ops = 1 if self.bias is not None else 0\n",
        "\n",
        "        params = output_channels * (kernel_ops + bias_ops)\n",
        "        flops = batch_size * params * output_height * output_width\n",
        "\n",
        "        list_conv.append(flops)\n",
        "\n",
        "    def linear_hook(self, input, output):\n",
        "        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n",
        "\n",
        "        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n",
        "        bias_ops = self.bias.nelement()\n",
        "\n",
        "        flops = batch_size * (weight_ops + bias_ops)\n",
        "        list_linear.append(flops)\n",
        "\n",
        "    def bn_hook(self, input, output):\n",
        "        list_bn.append(input[0].nelement())\n",
        "\n",
        "    def relu_hook(self, input, output):\n",
        "        list_relu.append(input[0].nelement())\n",
        "\n",
        "    def pooling_hook(self, input, output):\n",
        "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
        "        output_channels, output_height, output_width = output[0].size()\n",
        "\n",
        "        kernel_ops = self.kernel_size * self.kernel_size\n",
        "        bias_ops = 0\n",
        "        params = output_channels * (kernel_ops + bias_ops)\n",
        "        flops = batch_size * params * output_height * output_width\n",
        "\n",
        "        list_pooling.append(flops)\n",
        "\n",
        "    def foo(net):\n",
        "        childrens = list(net.children())\n",
        "        if not childrens:\n",
        "            if isinstance(net, torch.nn.Conv2d):\n",
        "                net.register_forward_hook(conv_hook)\n",
        "            if isinstance(net, torch.nn.Linear):\n",
        "                net.register_forward_hook(linear_hook)\n",
        "            if isinstance(net, torch.nn.BatchNorm2d):\n",
        "                net.register_forward_hook(bn_hook)\n",
        "            if isinstance(net, torch.nn.ReLU):\n",
        "                net.register_forward_hook(relu_hook)\n",
        "            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n",
        "                net.register_forward_hook(pooling_hook)\n",
        "            return\n",
        "        for c in childrens:\n",
        "            foo(c)\n",
        "\n",
        "    multiply_adds = False\n",
        "    list_conv, list_bn, list_relu, list_linear, list_pooling = [], [], [], [], []\n",
        "    foo(model)\n",
        "    if '0.4.' in torch.__version__ or '1.0' in torch.__version__:\n",
        "        if USE_GPU:\n",
        "            input = torch.cuda.FloatTensor(torch.rand(2, 3, input_size, input_size).cuda())\n",
        "        else:\n",
        "            input = torch.FloatTensor(torch.rand(2, 3, input_size, input_size))\n",
        "    else:\n",
        "        input = Variable(torch.rand(2, 3, input_size, input_size), requires_grad=True)\n",
        "    _ = model(input)\n",
        "\n",
        "    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling))\n",
        "\n",
        "    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9 / 2))\n",
        "\n",
        "\n",
        "def count_params(model, input_size=224):\n",
        "    # param_sum = 0\n",
        "    with open('models.txt', 'w') as fm:\n",
        "        fm.write(str(model))\n",
        "    calc_flops(model, input_size)\n",
        "\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "\n",
        "    print('The network has {} params.'.format(params))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6c0L4mQA9u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ColorAugmentation(object):\n",
        "    def __init__(self):\n",
        "        self.eig_vec = torch.Tensor([\n",
        "            [0.4009, 0.7192, -0.5675],\n",
        "            [-0.8140, -0.0045, -0.5808],\n",
        "            [0.4203, -0.6948, -0.5836],\n",
        "        ])\n",
        "        self.eig_val = torch.Tensor([[0.2175, 0.0188, 0.0045]])\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        assert tensor.size(0) == 3\n",
        "        alpha = torch.normal(mean=torch.zeros_like(self.eig_val)) * 0.1\n",
        "        quatity = torch.mm(self.eig_val * alpha, self.eig_vec)\n",
        "        tensor = tensor + quatity.view(3, 1, 1)\n",
        "        return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyIHtRVIA91A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2ee9becf-cd26-4b20-bf05-4d444200989f"
      },
      "source": [
        "parser = ArgumentParser(description='PyTorch ImageNet Training')\n",
        "parser.add_argument('data', metavar='DIR',type=str,nargs='+')\n",
        "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18')\n",
        "parser.add_argument('--config', default='/content/drive/My Drive/fishnet150.yaml')\n",
        "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 4)')\n",
        "parser.add_argument('--epochs', default=100, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('-b', '--batch-size', default=32, type=int,\n",
        "                    metavar='N', help='mini-batch size (default: 256)')\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
        "                    metavar='LR', help='initial learning rate')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum')\n",
        "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)')\n",
        "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
        "                    metavar='N', help='print frequency (default: 10)')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
        "                    help='evaluate models on validation set')\n",
        "#parser.add_argument('--train_image_list', default='A:\\\\HealthAnalytics\\\\image_Processing\\\\Project\\\\dataset', type=str, help='path to train image list')\n",
        "\n",
        "parser.add_argument('--input_size', default=224, type=int, help='img crop size')\n",
        "parser.add_argument('--image_size', default=256, type=int, help='ori img size')\n",
        "\n",
        "parser.add_argument('--model_name', default='', type=str, help='name of the models')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--model_name'], dest='model_name', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='name of the models', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l4eEeU7A93N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    global time_stp\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        #  pytorch 0.4.0 compatible\n",
        "        if '0.4.' in torch.__version__:\n",
        "            if USE_GPU:\n",
        "                input_var = torch.cuda.FloatTensor(input.cuda())\n",
        "                target_var = torch.cuda.LongTensor(target.cuda())\n",
        "            else:\n",
        "                input_var = torch.FloatTensor(input)\n",
        "                target_var = torch.LongTensor(target)\n",
        "        else:  # pytorch 0.3.1 or less compatible\n",
        "            if USE_GPU:\n",
        "                input = input.cuda()\n",
        "                target = target.cuda(async=True)\n",
        "            input_var = Variable(input)\n",
        "            target_var = Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "\n",
        "        loss = criterion(output, target_var)\n",
        "        prec1, prec5 = accuracy(output.data, target_var, topk=(1, 2))\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        reduced_prec1 = prec1.clone()\n",
        "        reduced_prec5 = prec5.clone()\n",
        "\n",
        "        top1.update(reduced_prec1[0])\n",
        "        top5.update(reduced_prec5[0])\n",
        "\n",
        "        reduced_loss = loss.data.clone()\n",
        "        losses.update(reduced_loss)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        #  check whether the network is well connected\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "           # with open('./logs/{}_{}.log'.format(time_stp, args.arch), 'a+') as flog:\n",
        "                line = 'Epoch: [{0}][{1}/{2}]\\t ' \\\n",
        "                       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
        "                       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
        "                       'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' \\\n",
        "                       'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
        "                        batch_time=batch_time, loss=losses, top1=top1, top5=top5)\n",
        "                print(line)\n",
        "                #flog.write('{}\\n'.format(line))\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    global time_stp\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        #  pytorch 0.4.0 compatible\n",
        "        if '0.4.' in torch.__version__:\n",
        "            with torch.no_grad():\n",
        "                if USE_GPU:\n",
        "                    input_var = torch.cuda.FloatTensor(input.cuda())\n",
        "                    target_var = torch.cuda.LongTensor(target.cuda())\n",
        "                else:\n",
        "                    input_var = torch.FloatTensor(input)\n",
        "                    target_var = torch.LongTensor(target)\n",
        "        else:  # pytorch 0.3.1 or less compatible\n",
        "            if USE_GPU:\n",
        "                input = input.cuda()\n",
        "                target = target.cuda(async=True)\n",
        "            input_var = Variable(input, volatile=True)\n",
        "            target_var = Variable(target, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(output.data, target_var, topk=(1, 2))\n",
        "        losses.update(loss.data, input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "        top5.update(prec5[0], input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        if i % args.print_freq == 0:\n",
        "            line = 'Test: [{0}/{1}]\\t' \\\n",
        "                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
        "                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
        "                   'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' \\\n",
        "                   'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(i, len(val_loader), batch_time=batch_time,\n",
        "                                                                   loss=losses, top1=top1, top5=top5)\n",
        "\n",
        "            #with open('logs/{}_{}.log'.format(time_stp, args.arch), 'a+') as flog:\n",
        "               # flog.write('{}\\n'.format(line))\n",
        "            print(line)\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = args.lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "    #print (maxk)\n",
        "    #print (batch_size)\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvNXO3jHA95n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0457ed4-8208-432b-ed35-3075681d1fb2"
      },
      "source": [
        "global args, best_prec1, USE_GPU\n",
        "time_stp = time.strftime(\"%Y-%m-%d_%H:%M:%S\", time.localtime())\n",
        "#args = parser.parse_args()\n",
        "args=parser.parse_args(['DIR','/content/drive/My Drive/'])\n",
        "model = fishnet150()\n",
        "model.cuda()\n",
        "#model_path='A:/HealthAnalytics/image_Processing/Project/fishnet150.tar'\n",
        "#checkpoint = torch.load(model_path)\n",
        "\n",
        "#best_prec1 = checkpoint['best_prec1']\n",
        "#model.load_state_dict(checkpoint['state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "with open(args.config) as f:\n",
        "        config = yaml.load(f)\n",
        "\n",
        "for k, v in config['common'].items():\n",
        "        setattr(args, k, v)\n",
        "\n",
        "    # create models\n",
        "if args.input_size != 224 or args.image_size != 256:\n",
        "        image_size = args.image_size\n",
        "        input_size = args.input_size\n",
        "else:\n",
        "        image_size = 256\n",
        "        input_size = 224\n",
        "print(\"Input image size: {}, test size: {}\".format(image_size, input_size))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input image size: 256, test size: 224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGxBhrWhA98b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a3d21ea-e415-4274-d649-18c91873940f"
      },
      "source": [
        "count_params(model)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay)\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  + Number of FLOPs: 6.45G\n",
            "The network has 23904514 params.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_76Ao61VA90K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loading code\n",
        "traindir = os.path.join(args.data[1],'Train/')\n",
        "valdir = os.path.join(args.data[1],'Validate/')\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "img_size = args.input_size\n",
        "\n",
        "ratio = 224.0 / float(img_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEDmwKPNBgXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.ImageFolder(\n",
        "        traindir,\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(img_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            ColorAugmentation(),\n",
        "            normalize,\n",
        "        ]))\n",
        "val_dataset = datasets.ImageFolder( valdir, transforms.Compose([\n",
        "        transforms.Resize(int(256 * ratio)),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bOLMleqBjOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   # if args.distributed:\n",
        "    #     train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    #     val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset)\n",
        "    # else:\n",
        "train_sampler = None\n",
        "val_sampler = None\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
        "        num_workers=0, pin_memory=(train_sampler is None), sampler=train_sampler)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "                                             num_workers=0, pin_memory=True, sampler=val_sampler)\n",
        "\n",
        "best_prec1 = 0\n",
        "if args.evaluate:\n",
        "        validate(val_loader, model, criterion)\n",
        "p=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6OUMOkqBmSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8bf3e471-40b9-4e37-baaf-aa04816dc6c5"
      },
      "source": [
        "\n",
        "for epoch in range(0,100):\n",
        "    #args.start_epoch, 25):#args.epochs):\n",
        "        # if args.distributed:\n",
        "        #     train_sampler.set_epoch(epoch)\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "        prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "# remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        " \n",
        "        save_name = '/content/drive/My Drive/Result1/'+str(p)+'best.pth.tar'.format(args.save_path, args.model_name, epoch) if is_best else\\\n",
        "            '/content/drive/My Drive/Result1/'+str(p)+'pth.tar'.format(args.save_path, args.model_name, epoch)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'arch': args.arch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }, filename=save_name)\n",
        "        p=p+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/106]\t Time 19.826 (19.826)\tLoss 5.4937 (5.4937)\tPrec@1 46.875 (46.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [0][10/106]\t Time 18.185 (19.826)\tLoss 3.4208 (28.2483)\tPrec@1 68.750 (51.136)\tPrec@5 100.000 (100.000)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}